# Exploiting-Euclidean-and-Hyperbolic-Embeddings-in-Knowledge-Graph-for-Link-Prediction

### original_data
It contains the original provided in https://smc-datachallenge.ornl.gov/data-challenges-2021/.

### processed_data
It contains the preprocessed data.

### tools
It contains three scripts:

1. **train.py -d <16/64> -c <n/p> -p <n/p>**

    ---run grid search on **Logistic Regression**, **Random Forest Classifier** and **Multi-Layer Perceptron Classifier**.

    ---The output is a Python dictionary recording the trained models and their evaluation metrics such as accuracy, recall, precision and F_1 score, which is saved in **/processed_data/** named as **model_performance_{16/64}_c-{n/p}_p-{n/p}.pkl**. Yadda yadda<a href="#note1" id="note1ref"><sup>1</sup></a>

2. **train_final_mlp.py**

    ---train a multi-layer perceptron classifier with hidden layers size to be (64, 32) on the 5-fold cross-validation of the whole training set **train_instances.pkl**.

    ---The output is 5 models[^2] trained and saved in **/final_model/** named as CV_models_{index}.pkl, and the scaler for preprocsseding features saved in **/final_model/** named as scaler_final.pkl.
    

3. **predict.py**

    ---use the 5 models to predict on all pairs of nodes.

    ---The outputs are **node_idx.pkl**, **predict_results.pkl**. 
    
    ---**node_idx.pkl** gives all nodes of concepts as a list.
    
    ---**predict_result.pkl** [^3] is a list, where the i-th element is a numpy array of size (N-i, 1) recording the probability that (node[i], node[j]) is a link for i+1 <= j <= N.

### final_model
It contains the information for the final prediction. 

### result
It contains the final result that gives all non-edge pair of nodes which have been predicted as future links and their probabilities.

<a id="note1" href="#note1ref"><sup>1</sup></a>Here is the footnote text.
