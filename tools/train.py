import numpy as np
import numpy as np
import pandas as pd
import pickle
import argparse
import os
import networkx as nx
import torch
from torch import nn
import time
from time import sleep
import sys

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score

PROJECT_ROOT_DIR = './../'
DATA_PATH = os.path.join(PROJECT_ROOT_DIR, 'data')
PROCESSED_DATA_PATH = os.path.join(PROJECT_ROOT_DIR, 'processed_data')

def load_data(dim, c_type, p_type):
    print(f'Start to load raw data..')
    with open(os.path.join(PROCESSED_DATA_PATH, 'train_instances.pkl'), 'rb') as file:
        train_data = pickle.load(file)
        train_instances = train_data['X']
        train_labels = train_data['y']
    print(f'train_instances.pkl loaded.')

    with open(os.path.join(PROCESSED_DATA_PATH, 'graph_info_500.pkl'), 'rb') as file:
        graph_data = pickle.load(file)
        graph = graph_data['graph']
        bet_cen_dict = graph_data['betweenness_centrality_500']
    print(f'graph_info_500.pkl loaded.')

    with open(os.path.join(PROCESSED_DATA_PATH, 'Jac_score.pkl'), 'rb') as file:
        jac_score = pickle.load(file)
    print(f'Jac_score.pkl loaded.')

    if p_type == 'p':
        avg_embed_file = 'concept_avg_embed_poincare.pkl'
    elif p_type == 'n':
        avg_embed_file = 'concept_avg_embed_nv.pkl'

    with open(os.path.join(PROCESSED_DATA_PATH, avg_embed_file), 'rb') as file:
        concept_to_avg_embed = pickle.load(file)
    print(f'{avg_embed_file} loaded.')


    if c_type == 'p':
        concept_embed_file = f'embedding_poincare_{dim}.pkl'
    elif c_type == 'n':
        concept_embed_file = f'embedding_n2v_{dim}.pkl'

    with open(os.path.join(PROCESSED_DATA_PATH, concept_embed_file), 'rb') as file:
        concept_to_embedding = pickle.load(file)
    print(f'{concept_embed_file} loaded.')

    n_bar = 50
    total_num = len(train_instances)
    start_time = time.time()

    X_data = np.zeros((total_num, 17 + dim * 2))

    for idx, instance in enumerate(train_instances):
        if idx % 5000 == 0:
            j = idx / total_num
            sys.stdout.write('\r')
            sys.stdout.write(f"[{'=' * int(n_bar * j):{n_bar}s}] {100 * j: .2f}% Used Time: {time.time() - start_time:.2f}s Processed Instances: {idx}")
            sys.stdout.flush()

        basic_info = np.array([graph.degree(instance[0]), graph.degree(instance[1]), bet_cen_dict[instance[0]], bet_cen_dict[instance[1]], jac_score[idx]]).reshape(1, -1)
        avg_embed = np.concatenate((concept_to_avg_embed[instance[0]], concept_to_avg_embed[instance[1]]), 1)
        #if p_type == 'p':
        #    avg_embed = np.array(avg_embeds[0]).reshape(1,-1)
        #elif p_type == 'n':
        #    avg_embed = np.concatenate((concept_to_avg_embed[instance[0]], concept_to_avg_embed[instance[1]]), 1)
        con0 = (concept_to_embedding[instance[0]]).reshape(1,-1)
        con1 = (concept_to_embedding[instance[1]]).reshape(1,-1)
        X_data[idx, :] = np.concatenate((basic_info, avg_embed, con0, con1), 1)

    j = idx / total_num
    sys.stdout.write('\r')
    sys.stdout.write(f"[{'=' * int(n_bar * j):{n_bar}s}] {100 * j: .2f}% Used Time: {time.time() - start_time:.2f}s Processed Instances: {idx}")
    sys.stdout.flush()

    y_data = np.array(train_labels)
    return X_data, y_data

def normalize(train, val, test):
    '''Standard scaling the frist 5 features, the others are coordinate of embeddings.'''
    scaler = StandardScaler
    train_numerical, train_embedding = train[:, :5], train[:, 5:]
    val_numerical, val_embedding = val[:, :5], val[:, 5:]
    test_numerical, test_embedding = test[:, :5], test[:, 5:]
    scaler = StandardScaler()
    train_numerical = scaler.fit_transform(train_numerical)
    val_numerical = scaler.transform(val_numerical)
    test_numerical = scaler.transform(test_numerical)
    return np.concatenate((train_numerical, train_embedding), axis = 1), np.concatenate((val_numerical, val_embedding), axis = 1), np.concatenate((test_numerical, test_embedding), axis = 1)

def lr(X_train, y_train, X_val, y_val):
    lr_clf = LogisticRegression(solver = 'liblinear', class_weight='balanced')

    #param_grid = [{'C': [1/10, 1/3, 1, 3, 10], 'max_iter': [1]}]
    param_grid = [{'C': [1/10, 1, 10], 'max_iter': [200, 1000]}]
    print(f'Start to gridsearch for LogisticRegression on {param_grid}...')
    grid_search = GridSearchCV(lr_clf, param_grid, scoring = 'accuracy', return_train_score = True)
    grid_search.fit(X_val, y_val)

    print(f'The best estimator is with {grid_search.best_params_}')
    lr_clf_best = grid_search.best_estimator_

    print(f'Start to train LogisticRegression with the train set...')
    lr_clf_best.fit(X_train, y_train)

    return lr_clf_best

def rnd(X_train, y_train, X_val, y_val):
    rnd_clf = RandomForestClassifier(class_weight = {0:1, 1:10})
    param_grid = [{'n_estimators': [200, 500, 1000]}]

    print(f'Start to gridsearch for RandomForestClassifier on {param_grid}...')
    grid_search = GridSearchCV(rnd_clf, param_grid, scoring = 'accuracy', return_train_score = True)
    grid_search.fit(X_val, y_val)

    print(f'The best estimator is with {grid_search.best_params_}')
    rnd_clf_best = grid_search.best_estimator_

    print(f'Start to train RandomForestClassifier with the train set...')
    rnd_clf_best.fit(X_train, y_train)

    return rnd_clf_best

def mlp(X_train, y_train, X_val, y_val):
    mlp_clf = MLPClassifier()
    #param_grid = [{'alpha': [0.0001, 0.001]}]
    param_grid = [{'hidden_layer_sizes': [(64, 32), (64, 32, 16)], 'alpha': [0.0001], 'learning_rate': ['constant', 'adaptive']}]

    print(f'Start to gridsearch for MLPClassifier on {param_grid}...')
    grid_search = GridSearchCV(mlp_clf, param_grid, scoring = 'accuracy', return_train_score = True)
    grid_search.fit(X_val, y_val)

    print(f'The best estimator is with {grid_search.best_params_}')
    mlp_clf_best = grid_search.best_estimator_

    print(f'Start to train MLPClassifier with the train set...')
    mlp_clf_best.fit(X_train, y_train)

    return mlp_clf_best



def get_performance(y_true, y_pred, record, model):
    record['Model'] = record.get('Model', []) + [model]
    record['Accuracy'] = record.get('Accuracy', []) + [accuracy_score(y_true, y_pred)]
    record['Confusion Matrix'] = record.get('Confusion Matrix', []) + [confusion_matrix(y_true, y_pred)]
    record['Precision Score(B)'] = record.get('Precision Score(B)', []) + [precision_score(y_true, y_pred)]
    record['Recall Score(B)'] = record.get('Recall Score(B)', []) + [recall_score(y_true, y_pred)]
    record['F1 Score(B)'] = record.get('F1 Score(B)', []) + [f1_score(y_true, y_pred)]
    record['Precision Score(W)'] = record.get('Precision Score(W)', []) + [precision_score(y_true, y_pred, average = 'weighted')]
    record['Recall Score(W)'] = record.get('Recall Score(W)', []) + [recall_score(y_true, y_pred, average = 'weighted')]
    record['F1 Score(W)'] = record.get('F1 Score(W)', []) + [f1_score(y_true, y_pred, average = 'weighted')]
    return record


def main():
    parser = argparse.ArgumentParser(description='Train')
    #parser.add_argument('-m', default = 'all', type = str, help='model slection')
    parser.add_argument('-d', default = 16, type = int, help='embedding dimension for concepts (16, 64, 128)')
    parser.add_argument('-c', default = 'p')
    parser.add_argument('-p', default = 'p')
    opt = parser.parse_args()

    X_data, y_data = load_data(opt.d, opt.c, opt.p)
    print('\n')
    print('Data loaded.')
    return

    performance_record = {'Model': [], 'Accuracy': [], 'Confusion Matrix': [], 'Precision Score(B)': [], 'Recall Score(B)': [], 'F1 Score(B)': [], 'Precision Score(W)': [], 'Recall Score(W)': [], 'F1 Score(W)': []}


    X_train_val, X_test, y_train_val, y_test = train_test_split(X_data, y_data, test_size=0.2, stratify=y_data)
    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, stratify=y_train_val)

    #Z-score the data
    X_train, X_val, X_test = normalize(X_train, X_val, X_test)

    print('Data preprocessed.')


    lr_clf = lr(X_train, y_train, X_val, y_val)
    y_pred_test_lr = lr_clf.predict(X_test)
    performance_record = get_performance(y_test, y_pred_test_lr, performance_record, lr_clf)


    rnd_clf = rnd(X_train, y_train, X_val, y_val)
    y_pred_test_rnd = rnd_clf.predict(X_test)
    performance_record = get_performance(y_test, y_pred_test_rnd, performance_record, rnd_clf)

    mlp_clf = mlp(X_train, y_train, X_val, y_val)
    y_pred_test_mlp = mlp_clf.predict(X_test)
    performance_record = get_performance(y_test, y_pred_test_mlp, performance_record, mlp_clf)

    with open(os.path.join(PROCESSED_DATA_PATH, f'model_performance_N2V_{opt.d}_c-{opt.c}_p-{opt.p}.pkl'), 'wb') as file:
        pickle.dump(performance_record, file)

    print(f'Performance saved at {os.path.join(PROCESSED_DATA_PATH, f"model_performance_N2V_{opt.d}_c-{opt.c}_p-{opt.p}.pkl")}.')


if __name__ == '__main__':
    main()
