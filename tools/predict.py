import numpy as np
import pickle
import os
import argparse
import networkx as nx

import time
import sys

from sklearn.neural_network import MLPClassifier

PROJECT_ROOT_DIR = './'
DATA_PATH = os.path.join(PROJECT_ROOT_DIR, 'data')
PROCESSED_DATA_PATH = os.path.join(PROJECT_ROOT_DIR, 'processed_data')
FINAL_MODEL_PATH = os.path.join(PROJECT_ROOT_DIR, 'final_model')

def load_graph():
    with open(os.path.join(PROCESSED_DATA_PATH, 'graph_info_500.pkl'), 'rb') as file:
        graph_data = pickle.load(file)
        graph = graph_data['graph']
        valid_nodes = list(set(graph.nodes()) - {'1', '2'})
        graph = graph.subgraph(valid_nodes)
        bet_cen_dict = graph_data['betweenness_centrality_500']
    print(f'graph_info_500.pkl loaded.')
    return graph, bet_cen_dict

def load_jac(graph):
    jac = dict()
    nodes = list(graph.nodes())
    start_time = time.time()

    for idx in range(len(nodes)):
        progress_bar(idx, len(nodes), 50, start_time)
        u = nodes[idx]
        n_u = set(graph.neighbors(u))
        dist_2_lists = [graph.neighbors(x) for x in n_u]
        dist_2_points = set().union(*dist_2_lists)
        for v in dist_2_points:
            pair = tuple(sorted((u,v)))
            if pair in jac:
                continue
            n_v = set(graph.neighbors(v))
            jac[pair] = len(n_u.intersection(n_v))/len(n_u.union(n_v))

    return jac


def load_concept_embedding():
    with open(os.path.join(PROCESSED_DATA_PATH, f'embedding_n2v_64.pkl'), 'rb') as file:
        concept_to_embedding = pickle.load(file)
    print(f'embedding_n2v_64.pkl loaded.')
    return concept_to_embedding

def load_paper_embedding():
    with open(os.path.join(PROCESSED_DATA_PATH, 'concept_avg_embed_poincare.pkl'), 'rb') as file:
        concept_to_avg_embed = pickle.load(file)
    print(f'paper_embedding_poincare.pkl loaded.')
    return concept_to_avg_embed

def load_models():
    models = []
    for idx in range(5):
        with open(os.path.join(FINAL_MODEL_PATH, f'cv_models_{idx}.pkl'), 'rb') as file:
            data = pickle.load(file)
            models.append(data['model'])
    return models

def create_feature(nodes, all_node_data, jac, idx):
    total_num = all_node_data.shape[0]
    X_data = np.zeros((total_num - idx - 1,145))
    #node data
    X_data[:,0] = all_node_data[idx, 0]
    X_data[:,2] = all_node_data[idx, 1]
    X_data[:, 5:11] = all_node_data[idx, 2:8]
    X_data[:, 17:81] = all_node_data[idx, 8:72]
    X_data[:, 1] = all_node_data[idx+1:, 0]
    X_data[:, 3] = all_node_data[idx+1:, 1]
    X_data[:, 11:17] = all_node_data[idx+1:, 2:8]
    X_data[:, 81:145] = all_node_data[idx+1:, 8:72]
    #jac data
    u = nodes[idx]
    jac_column = np.array([jac.get(tuple(sorted((u,v))), t) for t, v in enumerate(nodes[idx+1:])])
    X_data[:, 4] = jac_column

    return X_data

def progress_bar(idx, total_num, n_bar, start_time):
    j = idx / total_num
    sys.stdout.write('\r')
    sys.stdout.write(f"[{'=' * int(n_bar * j):{n_bar}s}] {100 * j: .2f}% Used Time: {time.time() - start_time:.2f}s Processed Instances: {idx}")
    sys.stdout.flush()
    return


def main():
    graph, bet_cen_dict = load_graph()
    jac = load_jac(graph)
    concept_to_avg_embed = load_paper_embedding()
    concept_to_embedding = load_concept_embedding()
    return
    models = load_models()

    nodes = list(graph.nodes())

    total_num = len(nodes)
    all_node_data = np.zeros((total_num, 72))
    for idx, node in enumerate(nodes):
        all_node_data[idx, 0] = graph.degree(node)
        all_node_data[idx, 1] = bet_cen_dict[node]
        all_node_data[idx, 2:8] = concept_to_avg_embed[node]
        all_node_data[idx, 8:72] = concept_to_embedding[node]

    with open(os.path.join(FINAL_MODEL_PATH, 'node_index.pkl'), 'wb') as file:
        pickle.dump(nodes, file)


    print(f'Data prepared')
    with open(os.path.join(FINAL_MODEL_PATH, 'scaler_final.pkl'), 'rb') as file:
        scaler = pickle.load(file)

    save_dict = dict()
    n_bar = 50
    start_time = time.time()
    results = []
    for idx, node in enumerate(nodes[:-1]):
        progress_bar(idx, total_num, n_bar, start_time)
        X_data = create_feature(nodes, all_node_data, jac, idx)
        X_numerical = scaler.transform(X_data[:, :5])
        X_embedding = X_data[:, 5:]
        X_data = np.concatenate((X_numerical, X_embedding), axis = 1)

        result = np.zeros((X_data.shape[0], 1))
        for model in models:
            result += (model.predict_proba(X_data))[:, 1:2]
        result = result/5
        results.append(result)
        if idx == 1000 and idx > 0:
            with open(os.path.join(FINAL_MODEL_PATH, 'predict_results.pkl'), 'wb') as file:
                pickle.dump(results, file)

    with open(os.path.join(FINAL_MODEL_PATH, 'predict_results.pkl'), 'wb') as file:
        pickle.dump(results, file)


if __name__ == '__main__':
    main()
